{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "from keras import Model,Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "#conda install -c anaconda keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train/hot_dog/1.jpg', 'train/hot_dog/2.jpg', 'train/not_hot_dog/1.jpg', 'train/not_hot_dog/2.jpg']\n",
      "[[1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "['test/hot_dog/1.jpg', 'test/hot_dog/2.jpg', 'test/not_hot_dog/1.jpg', 'test/not_hot_dog/2.jpg']\n",
      "[[1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "classes=[np.array([1,0]),np.array([0,1])]\n",
    "hot_dog_image_dir = 'train/hot_dog/'\n",
    "hot_dog_paths = [''.join(hot_dog_image_dir+filename) for filename in \n",
    "                            ['1.jpg',\n",
    "                             '2.jpg']]\n",
    "\n",
    "not_hot_dog_image_dir = 'train/not_hot_dog/'\n",
    "not_hot_dog_paths = [''.join(not_hot_dog_image_dir+filename) for filename in\n",
    "                            ['1.jpg',\n",
    "                             '2.jpg']]\n",
    "\n",
    "image_paths_train = hot_dog_paths + not_hot_dog_paths\n",
    "y_dog=np.ones((len(hot_dog_paths),1),dtype=int)\n",
    "y_not=np.zeros((len(not_hot_dog_paths),1),dtype=int)\n",
    "y_train=np.concatenate((y_dog, y_not), axis=0)\n",
    "print(image_paths_train)\n",
    "print(y_train)\n",
    "\n",
    "###############################################################################################################\n",
    "hot_dog_image_dir_test = 'test/hot_dog/'\n",
    "hot_dog_paths_test = [''.join(hot_dog_image_dir_test+filename) for filename in \n",
    "                            ['1.jpg',\n",
    "                             '2.jpg']]\n",
    "\n",
    "not_hot_dog_image_dir_test = 'test/not_hot_dog/'\n",
    "not_hot_dog_paths_test = [''.join(not_hot_dog_image_dir_test+filename) for filename in\n",
    "                            ['1.jpg',\n",
    "                             '2.jpg']]\n",
    "\n",
    "image_paths_test = hot_dog_paths_test + not_hot_dog_paths_test\n",
    "y_dog_test=np.ones((len(hot_dog_paths_test),1),dtype=int)\n",
    "y_dog_not=np.zeros((len(not_hot_dog_paths_test),1),dtype=int)\n",
    "y_test=np.concatenate((y_dog_test, y_dog_not), axis=0)\n",
    "print(image_paths_test)\n",
    "print(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadpath(image_paths,xsize=16,ysize=16):\n",
    "    X=[]\n",
    "    input_shape=-1\n",
    "    for location in image_paths:\n",
    "        img=load_img(location,target_size=(xsize,ysize))\n",
    "        sx=img_to_array(img) #(512, 382, 3)\n",
    "#         print(x.shape)\n",
    "        if(input_shape==-1):  #input_shape needs to be 3 dimension, kernel will add in the fourth by itself WOAHHH\n",
    "            input_shape=sx.shape\n",
    "        sx=sx.reshape((1,)+sx.shape) #(1, 512, 382, 3)\n",
    "#         print(sx.shape)\n",
    "#         print(sx)\n",
    "        if(X==[]):\n",
    "            X=sx\n",
    "        else:\n",
    "            np.append(X, sx)\n",
    "    \n",
    "    return input_shape,X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/administrator/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "input_shape,x_train=loadpath(image_paths_train)\n",
    "input_shape,x_test=loadpath(image_paths_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# def weirdfilters(x,num_gen,ImageDataGenerator(\n",
    "#             rotation_range=40,\n",
    "#             width_shift_range=0.2,\n",
    "#             height_shift_range=0.2,\n",
    "#             rescale=1./255,\n",
    "#             shear_range=0.2,\n",
    "#             zoom_range=0.2,\n",
    "#             horizontal_flip=True,\n",
    "#             fill_mode='nearest')\n",
    "                 \n",
    "                 \n",
    "#     datagen = ImageDataGenerator(\n",
    "#             rotation_range=40,\n",
    "#             width_shift_range=0.2,\n",
    "#             height_shift_range=0.2,\n",
    "#             rescale=1./255,\n",
    "#             shear_range=0.2,\n",
    "#             zoom_range=0.2,\n",
    "#             horizontal_flip=True,\n",
    "#             fill_mode='nearest')\n",
    "#     count=0\n",
    "#     while(count!=x):\n",
    "#         count+=1\n",
    "#         datagen.flow(x,batch_size=1,save_to_dir'preview',save_prefix='cat',save_format='jpeg')\n",
    "        \n",
    "    \n",
    "        \n",
    "#     return datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Squential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-1384e1f5bad9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Misleading model1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mM0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSquential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mM0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Squential' is not defined"
     ]
    }
   ],
   "source": [
    "from keras import Model,Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, MaxPooling1D\n",
    "# Misleading model1\n",
    "\n",
    "M0 = Sequential()\n",
    "\n",
    "M0.add(MaxPooling1D(pool_size=(3,3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 150,721\n",
      "Trainable params: 150,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Model,Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "# Basic model1\n",
    "\n",
    "M1 = Sequential()\n",
    "\n",
    "M1.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "\n",
    "M1.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "M1.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "M1.add(Flatten())\n",
    "\n",
    "M1.add(Dense(128, activation='relu'))\n",
    "\n",
    "M1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "M1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.loss = []\n",
    "        self.val_acc = []\n",
    "        self.acc = []\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.loss.append(logs.get('loss'))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "\n",
    "history_cb = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input arrays should have the same number of samples as target arrays. Found 1 input samples and 4 target samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-0b8382ea8a02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mM1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mM1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/administrator/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/administrator/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    802\u001b[0m             ]\n\u001b[1;32m    803\u001b[0m             \u001b[0;31m# Check that all arrays have the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0mcheck_array_length_consistency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m                 \u001b[0;31m# Additional checks to avoid users mistakenly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/administrator/anaconda2/lib/python2.7/site-packages/keras/engine/training_utils.pyc\u001b[0m in \u001b[0;36mcheck_array_length_consistency\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    235\u001b[0m                          \u001b[0;34m'the same number of samples as target arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                          \u001b[0;34m'Found '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input samples '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                          'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         raise ValueError('All sample_weight arrays should have '\n",
      "\u001b[0;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 1 input samples and 4 target samples."
     ]
    }
   ],
   "source": [
    "import keras\n",
    "batch_size=12\n",
    "epochs=1\n",
    "M1.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adadelta(lr=0.01),metrics=['accuracy'])\n",
    "\n",
    "M1.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test),callbacks=[history_cb])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
