{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "from keras import Model,Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "#conda install -c anaconda keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "hot_dog_image_dir = 'train/hot_dog/'\n",
    "hot_dog_paths = [''.join(hot_dog_image_dir+filename) for filename in \n",
    "                            os.listdir(hot_dog_image_dir)]\n",
    "\n",
    "not_hot_dog_image_dir = 'train/not_hot_dog/'\n",
    "not_hot_dog_paths = [''.join(not_hot_dog_image_dir+filename) for filename in\n",
    "                            os.listdir(not_hot_dog_image_dir)]\n",
    "\n",
    "image_paths_train = hot_dog_paths + not_hot_dog_paths\n",
    "y_dog=np.ones((len(hot_dog_paths),1),dtype=int)\n",
    "y_not=np.zeros((len(not_hot_dog_paths),1),dtype=int)\n",
    "y_train=np.concatenate((y_dog, y_not), axis=0)\n",
    "# print(image_paths_train)\n",
    "# print(y_train)\n",
    "\n",
    "###############################################################################################################\n",
    "hot_dog_image_dir_test = 'test/hot_dog/'\n",
    "hot_dog_paths_test = [''.join(hot_dog_image_dir_test+filename) for filename in \n",
    "                            os.listdir(hot_dog_image_dir_test)]\n",
    "\n",
    "not_hot_dog_image_dir_test = 'test/not_hot_dog/'\n",
    "not_hot_dog_paths_test = [''.join(not_hot_dog_image_dir_test+filename) for filename in\n",
    "                            os.listdir(not_hot_dog_image_dir_test)]\n",
    "\n",
    "image_paths_test = hot_dog_paths_test + not_hot_dog_paths_test\n",
    "y_dog_test=np.ones((len(hot_dog_paths_test),1),dtype=int)\n",
    "y_dog_not=np.zeros((len(not_hot_dog_paths_test),1),dtype=int)\n",
    "y_test=np.concatenate((y_dog_test, y_dog_not), axis=0)\n",
    "# print(image_paths_test)\n",
    "# print(y_test)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadpath(image_paths,xsize=16,ysize=16):\n",
    "    X=[]\n",
    "    for location in image_paths:\n",
    "        img=load_img(location,target_size=(xsize,ysize))\n",
    "        sx=img_to_array(img) #(512, 382, 3)\n",
    "#         print(x.shape)\n",
    "#         sx=sx.reshape((1,)+sx.shape) #(1, 512, 382, 3)\n",
    "#         print(sx.shape)\n",
    "#         print(sx)\n",
    "        X.append(sx)\n",
    "        input_shape=sx.shape   \n",
    "    return input_shape,np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# def weirdfilters(x,num_gen,ImageDataGenerator(\n",
    "#             rotation_range=40,\n",
    "#             width_shift_range=0.2,\n",
    "#             height_shift_range=0.2,\n",
    "#             rescale=1./255,\n",
    "#             shear_range=0.2,\n",
    "#             zoom_range=0.2,\n",
    "#             horizontal_flip=True,\n",
    "#             fill_mode='nearest')\n",
    "                 \n",
    "                 \n",
    "#     datagen = ImageDataGenerator(\n",
    "#             rotation_range=40,\n",
    "#             width_shift_range=0.2,\n",
    "#             height_shift_range=0.2,\n",
    "#             rescale=1./255,\n",
    "#             shear_range=0.2,\n",
    "#             zoom_range=0.2,\n",
    "#             horizontal_flip=True,\n",
    "#             fill_mode='nearest')\n",
    "#     count=0\n",
    "#     while(count!=x):\n",
    "#         count+=1\n",
    "#         datagen.flow(x,batch_size=1,save_to_dir'preview',save_prefix='cat',save_format='jpeg')\n",
    "        \n",
    "    \n",
    "        \n",
    "#     return datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#        ,@@@@@@@@@@,,@@@@@@@%  .#&@@@&&.,@@@@@@@@@@,      %@@@@@@%*   ,@@@%     .#&@@@&&.  *&@@@@&(  ,@@@@@@@%  %@@@@@,     ,@@,          \n",
    "            ,@@,    ,@@,      ,@@/   ./.    ,@@,          %@%   ,&@# .&@&@@(   .@@/   ./. #@&.  .,/  ,@@,       %@%  *&@&.  ,@@,          \n",
    "            ,@@,    ,@@&%%%%. .&@@/,        ,@@,          %@%   ,&@# %@& /@@,  .&@@/,     (@@&%(*.   ,@@&%%%%.  %@%    &@#  ,@@,          \n",
    "            ,@@,    ,@@/,,,,    ./#&@@@(    ,@@,          %@@@@@@%* /@@,  #@&.   ./#&@@@(   *(%&@@&. ,@@/,,,,   %@%    &@#  .&&.          \n",
    "            ,@@,    ,@@,      ./,   .&@#    ,@@,          %@%      ,@@@@@@@@@% ./.   .&@# /*.   /@@. ,@@,       %@%  *&@&.   ,,           \n",
    "            ,@@,    ,@@@@@@@% .#&@@@@&/     ,@@,          %@%     .&@#     ,@@/.#&@@@@&/   /%&@@@@.  ,@@@@@@@%  %@@@@@.     ,@@,          \n",
    ",*************,,*/(((((//,,*(#%%%%%%%%%%%%%%%#(*,,,****************************************************,*/(((((((((/((((////****/((##%%%%%%\n",
    ",*************,,//((((((//,,*(%%%%%%%%%%%%%%%%%##/*****************************************************,,*/(///(//////****//((##%%%%%%%%%%%\n",
    ",************,,*/(((((((//***/#%%%%%%%%%%%%%%%%%%%#(/***************************************************,*//////////*//((#%%%%%%%%%%%%%%%%%\n",
    ",***********,,*////////////***/##%%%%%%%%%%%%%%%%%%%##(*,***********************************************,,*////////(###%%%%%%%%%%%%%%%%%%%%\n",
    ",**********,,,*/*******//////**/(#%%%%%%%%%%%%%%%%%%%%%#(/**********************************************,,,***/(##%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    ",*********,,,,*************///***/(#%%%%%%%%%%%%%%%%%%%%%%#(/***********************************,****,****/((#%%%%%%%%%%%%%%%%%%%%%%%%%%%%#\n",
    ",*********,,,***************//****/(##%%%%%%%%%%%%%%%%%%%%%%##//**************//////////////////////((#####%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(\n",
    ",********,,,,***********************/(#%%%%%%%%%%%%%%%%%%%%%%%##################%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(/\n",
    ",*******,..,***********************,,*/##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%###((//\n",
    ",*******,.,,***********************,,,,*(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(//**//\n",
    ",******,.,,,************************,,,,*/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(//*******\n",
    ",*****,,,,,********,***,,,,,,,,,,,,*,,,,,,*/(######%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(/**********\n",
    ",*****,..,*******,,,,,,,,,,,,,,,,,,,,,,*,,,,*///((#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%###(/************\n",
    ",*****,,,*******,,,,,*,,,,,,,,,,,,,,,,,****,,,*/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#######(//**************\n",
    ",****,.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,**,,,/(%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#((//******************\n",
    ",***,..,,,,,,,,,,,,,,,,,,,,,,,,,,,,,..,,,,,,,*(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*******************\n",
    ",**,,.,,,,,,,,,,,,,,,,,,,,,,,,,,.......,,,,,,/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#####%%%%%%%%%%%%%%%%#(/******************\n",
    ",**,..,,,,,,,,,,,,,,,,,,,,,,,,,......,,,*,,,*(#%%%%%%%%##(((/(##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(((/*/((#%%%%%%%%%%%%%%#(/*****************\n",
    ",*,..,,,,,,,,,,,,,,,,,,,,,,,,,,,.....,,**,,*/#%%%%%%%##((((*,**/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%##((##/,,,*(#%%%%%%%%%%%%%%#(*****************\n",
    ".*,.,,,**,,,,,,,,,,,,,,,,,,,,,,,,,,*****,,,/(%%%%%%%%#(//(#/,..*/#%%%%%%%%%%%%%%%%%%%%%%%%%%%#(//(#/,..,/(#%%%%%%%%%%%%%%#/*****///////////\n",
    ".,..,,,,,,,,,,,,,,,,,,,,,,,,,,*,,*******,,,(#%%%%%%%%#(*,,,....,/#%%%%%%%%%%%%%%%%%%%%%%%%%%%#(*,,,....,/(#%%%%%%%%%%%%%%#(*,**////////////\n",
    ".,..,,,,,,,,,...........,,,,,,*,********,,*(#%%%%%%%%%#(/*,,...,/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*,,..,*/##%%%%%%%%%%%%%%%#(***////////////\n",
    "...,,,,,,,................,,*,**********,,/#%%%%%%%%%%%%#((////((#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##((///(#%%%%%%%%%%%%%%%%%%(/**////////////\n",
    " ..,,,,,,.................,,,**********,,*(#%%%%%%%%%%%%%%%%%%#%%%%%%%%#((///((#%%%%%%%%%%%%%%%%%%%%%#%%%%%%%%%%%%%%%%%%%%%#/**////////////\n",
    ".,,,,,,,,.................,,***********,,/(####%%%%%%%%%%%%%%%%%%%%%%%%#(/*,,,*(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*////////////\n",
    ".,***,,,,,,..............,,,**********,..,***//((##%%%%%%%%%%%%%%%%%%%%%%%##((##%%%%%%%%%%%%%%%%%%%%%%%%%##(((((((((###%%%%%#/**///////////\n",
    ".*****,,,,,,,,,,,,,,,,,,,*************,..,*******/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##///*//////((#%%%%%#(**///////////\n",
    ".****************/******/***////*****,.,*///////**/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(////////////(#%%%%%#/**//////////\n",
    ".***********************/////*******,..,*//////////(#%%%%%%%%%%%%%%%%%%%%##########%%%%%%%%%%%%%%%%%%%%#(///////////*/(#%%%%%#(***/////////\n",
    ".************************///********,..,*//////////#%%%%%%%%%%%%%%%%%%#(//*****///(((##%%%%%%%%%%%%%%%%#(///////////**/##%%%%##/***////////\n",
    ".***********************************,.,,***///////(#%%%%%%%%%%%%%%%%#(/*,,,*//((((////(#%%%%%%%%%%%%%%%#((////////////(#%%%%%%#(*********//\n",
    ",***********,,,*,,*,,**************,,,*//******//(#%%%%%%%%%%%%%%%%%#(*,,*/(((#####(((((#%%%%%%%%%%%%%%%##///////////(#%%%%%%%%#(***///////\n",
    ",*************,,**,,,************,,,,,/(##((((####%%%%%%%%%%%%%%%%%%%(/**/(((#((((#((//(#%%%%%%%%%%%%%%%%%#(((((((((##%%%%%%%%%%#/**///////\n",
    ",******************************,,,,,,,*(#%#%%%%%%%%%%%%%%%%%%%%%%%%%%#(**/((#(#(((#((//(#%%%%%%%%%%%%%%%%%%%%%%%#%#%%%%%%%%%%%%%#(**///////\n",
    ",*************,**************,****,,,,,/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*/((((#((((///(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%(/*///////\n",
    ",*************************************,*/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(////////////(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#/**/////*\n",
    ",******////****///////////////////////***/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%####(((((((###%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(********\n",
    ".,*,****///////////////////////////////***/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*******\n",
    ".,,,,*****//////////////////////////*******(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(*******\n",
    ".,,,,,,***********/////////////////********/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%(*******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(798, 128, 128, 3)\n",
      "(200, 128, 128, 3)\n",
      "(798, 1)\n",
      "(200, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_shape,x=loadpath(image_paths_train+image_paths_test,128,128)\n",
    "y=np.concatenate((y_train, y_test), axis=0)\n",
    "# from keras.utils import to_categorical\n",
    "# y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)\n",
    "\n",
    "# y_train=y_train.transpose()\n",
    "# y_test=y_test.transpose()\n",
    "\n",
    "# y_train=np.matrix(y_train)\n",
    "# y_test=np.matrix(y_test)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42,shuffle=True)\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 124, 124, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 41, 41, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 107584)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               13770880  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 13,790,401\n",
      "Trainable params: 13,790,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Model,Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "# Basic model1\n",
    "\n",
    "M1 = Sequential()\n",
    "\n",
    "M1.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "\n",
    "M1.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "M1.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "M1.add(Flatten())\n",
    "\n",
    "M1.add(Dense(128, activation='relu'))\n",
    "\n",
    "M1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "M1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.loss = []\n",
    "        self.val_acc = []\n",
    "        self.acc = []\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.loss.append(logs.get('loss'))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "\n",
    "history_cb = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 798 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4936 - acc: 0.5063 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 2/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4935 - acc: 0.5063 - val_loss: 0.4767 - val_acc: 0.4800\n",
      "Epoch 3/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4935 - acc: 0.4862 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 4/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4937 - acc: 0.5063 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 5/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4937 - acc: 0.5063 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 6/100\n",
      "798/798 [==============================] - 35s 44ms/step - loss: 0.4937 - acc: 0.5063 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 7/100\n",
      "798/798 [==============================] - 35s 44ms/step - loss: 0.4937 - acc: 0.5063 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 8/100\n",
      "798/798 [==============================] - 35s 44ms/step - loss: 0.4937 - acc: 0.5063 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 9/100\n",
      "798/798 [==============================] - 35s 44ms/step - loss: 0.4937 - acc: 0.5063 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 10/100\n",
      "798/798 [==============================] - 35s 44ms/step - loss: 0.4937 - acc: 0.5063 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 11/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4937 - acc: 0.5063 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 12/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4937 - acc: 0.5063 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 13/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4937 - acc: 0.5063 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 14/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4937 - acc: 0.5063 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 15/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4936 - acc: 0.5063 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 16/100\n",
      "798/798 [==============================] - 32s 40ms/step - loss: 0.4935 - acc: 0.5063 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 17/100\n",
      "798/798 [==============================] - 32s 40ms/step - loss: 0.4932 - acc: 0.5063 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 18/100\n",
      "798/798 [==============================] - 32s 40ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 19/100\n",
      "798/798 [==============================] - 30s 38ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 20/100\n",
      "798/798 [==============================] - 31s 38ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 21/100\n",
      "798/798 [==============================] - 30s 38ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 22/100\n",
      "798/798 [==============================] - 31s 38ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 23/100\n",
      "798/798 [==============================] - 32s 40ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 24/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 25/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 26/100\n",
      "798/798 [==============================] - 34s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 27/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 28/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 29/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 30/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 31/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 32/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 33/100\n",
      "798/798 [==============================] - 34s 43ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 34/100\n",
      "798/798 [==============================] - 35s 44ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 35/100\n",
      "798/798 [==============================] - 34s 43ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 36/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 37/100\n",
      "798/798 [==============================] - 34s 43ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 38/100\n",
      "798/798 [==============================] - 32s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 39/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 40/100\n",
      "798/798 [==============================] - 34s 43ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 41/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 42/100\n",
      "798/798 [==============================] - 32s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 43/100\n",
      "798/798 [==============================] - 32s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 44/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 45/100\n",
      "798/798 [==============================] - 32s 40ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 46/100\n",
      "798/798 [==============================] - 32s 40ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 47/100\n",
      "798/798 [==============================] - 31s 39ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 48/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 49/100\n",
      "798/798 [==============================] - 31s 39ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 50/100\n",
      "798/798 [==============================] - 31s 39ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 51/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 52/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 53/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 54/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 55/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 56/100\n",
      "798/798 [==============================] - 34s 43ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 57/100\n",
      "798/798 [==============================] - 32s 40ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 58/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 59/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 60/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 62/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 63/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 64/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 65/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 66/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 67/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 68/100\n",
      "798/798 [==============================] - 32s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 69/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 70/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 71/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 72/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 73/100\n",
      "798/798 [==============================] - 32s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 74/100\n",
      "798/798 [==============================] - 32s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 75/100\n",
      "798/798 [==============================] - 32s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 76/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 77/100\n",
      "798/798 [==============================] - 32s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 78/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 79/100\n",
      "798/798 [==============================] - 32s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 80/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 81/100\n",
      "798/798 [==============================] - 34s 43ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 82/100\n",
      "798/798 [==============================] - 35s 43ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 83/100\n",
      "798/798 [==============================] - 34s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 84/100\n",
      "798/798 [==============================] - 34s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 85/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 86/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 87/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 88/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 89/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 90/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 91/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 92/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 93/100\n",
      "798/798 [==============================] - 34s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 94/100\n",
      "798/798 [==============================] - 34s 43ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 95/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 96/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 97/100\n",
      "798/798 [==============================] - 33s 41ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 98/100\n",
      "798/798 [==============================] - 33s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 99/100\n",
      "798/798 [==============================] - 34s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 100/100\n",
      "798/798 [==============================] - 34s 42ms/step - loss: 0.4925 - acc: 0.5075 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Test loss: 0.525\n",
      "Test accuracy: 0.475\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "batch_size=256\n",
    "epochs=100\n",
    "M1.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adadelta(lr=0.01),metrics=['accuracy'])\n",
    "\n",
    "M1.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test),callbacks=[history_cb])\n",
    "\n",
    "score = M1.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1.save('Skynet_M1')\n",
    "# model = keras.models.load_model('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "model1Hist = history_cb\n",
    "plt.plot(model1Hist.acc)\n",
    "plt.plot(model1Hist.val_acc)\n",
    "plt.title('Model 1')\n",
    "plt.legend((\"Training\", \"Testing\"), loc=\"best\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#        ,@@@@@@@@@@,,@@@@@@@%  .#&@@@&&.,@@@@@@@@@@,      %@@@@@@%*   ,@@@%     .#&@@@&&.  *&@@@@&(  ,@@@@@@@%  %@@@@@,     ,@@,          \n",
    "            ,@@,    ,@@,      ,@@/   ./.    ,@@,          %@%   ,&@# .&@&@@(   .@@/   ./. #@&.  .,/  ,@@,       %@%  *&@&.  ,@@,          \n",
    "            ,@@,    ,@@&%%%%. .&@@/,        ,@@,          %@%   ,&@# %@& /@@,  .&@@/,     (@@&%(*.   ,@@&%%%%.  %@%    &@#  ,@@,          \n",
    "            ,@@,    ,@@/,,,,    ./#&@@@(    ,@@,          %@@@@@@%* /@@,  #@&.   ./#&@@@(   *(%&@@&. ,@@/,,,,   %@%    &@#  .&&.          \n",
    "            ,@@,    ,@@,      ./,   .&@#    ,@@,          %@%      ,@@@@@@@@@% ./.   .&@# /*.   /@@. ,@@,       %@%  *&@&.   ,,           \n",
    "            ,@@,    ,@@@@@@@% .#&@@@@&/     ,@@,          %@%     .&@#     ,@@/.#&@@@@&/   /%&@@@@.  ,@@@@@@@%  %@@@@@.     ,@@,          \n",
    ",*************,,*/(((((//,,*(#%%%%%%%%%%%%%%%#(*,,,****************************************************,*/(((((((((/((((////****/((##%%%%%%\n",
    ",*************,,//((((((//,,*(%%%%%%%%%%%%%%%%%##/*****************************************************,,*/(///(//////****//((##%%%%%%%%%%%\n",
    ",************,,*/(((((((//***/#%%%%%%%%%%%%%%%%%%%#(/***************************************************,*//////////*//((#%%%%%%%%%%%%%%%%%\n",
    ",***********,,*////////////***/##%%%%%%%%%%%%%%%%%%%##(*,***********************************************,,*////////(###%%%%%%%%%%%%%%%%%%%%\n",
    ",**********,,,*/*******//////**/(#%%%%%%%%%%%%%%%%%%%%%#(/**********************************************,,,***/(##%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    ",*********,,,,*************///***/(#%%%%%%%%%%%%%%%%%%%%%%#(/***********************************,****,****/((#%%%%%%%%%%%%%%%%%%%%%%%%%%%%#\n",
    ",*********,,,***************//****/(##%%%%%%%%%%%%%%%%%%%%%%##//**************//////////////////////((#####%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(\n",
    ",********,,,,***********************/(#%%%%%%%%%%%%%%%%%%%%%%%##################%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(/\n",
    ",*******,..,***********************,,*/##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%###((//\n",
    ",*******,.,,***********************,,,,*(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(//**//\n",
    ",******,.,,,************************,,,,*/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(//*******\n",
    ",*****,,,,,********,***,,,,,,,,,,,,*,,,,,,*/(######%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(/**********\n",
    ",*****,..,*******,,,,,,,,,,,,,,,,,,,,,,*,,,,*///((#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%###(/************\n",
    ",*****,,,*******,,,,,*,,,,,,,,,,,,,,,,,****,,,*/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#######(//**************\n",
    ",****,.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,**,,,/(%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#((//******************\n",
    ",***,..,,,,,,,,,,,,,,,,,,,,,,,,,,,,,..,,,,,,,*(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*******************\n",
    ",**,,.,,,,,,,,,,,,,,,,,,,,,,,,,,.......,,,,,,/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#####%%%%%%%%%%%%%%%%#(/******************\n",
    ",**,..,,,,,,,,,,,,,,,,,,,,,,,,,......,,,*,,,*(#%%%%%%%%##(((/(##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(((/*/((#%%%%%%%%%%%%%%#(/*****************\n",
    ",*,..,,,,,,,,,,,,,,,,,,,,,,,,,,,.....,,**,,*/#%%%%%%%##((((*,**/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%##((##/,,,*(#%%%%%%%%%%%%%%#(*****************\n",
    ".*,.,,,**,,,,,,,,,,,,,,,,,,,,,,,,,,*****,,,/(%%%%%%%%#(//(#/,..*/#%%%%%%%%%%%%%%%%%%%%%%%%%%%#(//(#/,..,/(#%%%%%%%%%%%%%%#/*****///////////\n",
    ".,..,,,,,,,,,,,,,,,,,,,,,,,,,,*,,*******,,,(#%%%%%%%%#(*,,,....,/#%%%%%%%%%%%%%%%%%%%%%%%%%%%#(*,,,....,/(#%%%%%%%%%%%%%%#(*,**////////////\n",
    ".,..,,,,,,,,,...........,,,,,,*,********,,*(#%%%%%%%%%#(/*,,...,/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*,,..,*/##%%%%%%%%%%%%%%%#(***////////////\n",
    "...,,,,,,,................,,*,**********,,/#%%%%%%%%%%%%#((////((#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##((///(#%%%%%%%%%%%%%%%%%%(/**////////////\n",
    " ..,,,,,,.................,,,**********,,*(#%%%%%%%%%%%%%%%%%%#%%%%%%%%#((///((#%%%%%%%%%%%%%%%%%%%%%#%%%%%%%%%%%%%%%%%%%%%#/**////////////\n",
    ".,,,,,,,,.................,,***********,,/(####%%%%%%%%%%%%%%%%%%%%%%%%#(/*,,,*(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*////////////\n",
    ".,***,,,,,,..............,,,**********,..,***//((##%%%%%%%%%%%%%%%%%%%%%%%##((##%%%%%%%%%%%%%%%%%%%%%%%%%##(((((((((###%%%%%#/**///////////\n",
    ".*****,,,,,,,,,,,,,,,,,,,*************,..,*******/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##///*//////((#%%%%%#(**///////////\n",
    ".****************/******/***////*****,.,*///////**/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(////////////(#%%%%%#/**//////////\n",
    ".***********************/////*******,..,*//////////(#%%%%%%%%%%%%%%%%%%%%##########%%%%%%%%%%%%%%%%%%%%#(///////////*/(#%%%%%#(***/////////\n",
    ".************************///********,..,*//////////#%%%%%%%%%%%%%%%%%%#(//*****///(((##%%%%%%%%%%%%%%%%#(///////////**/##%%%%##/***////////\n",
    ".***********************************,.,,***///////(#%%%%%%%%%%%%%%%%#(/*,,,*//((((////(#%%%%%%%%%%%%%%%#((////////////(#%%%%%%#(*********//\n",
    ",***********,,,*,,*,,**************,,,*//******//(#%%%%%%%%%%%%%%%%%#(*,,*/(((#####(((((#%%%%%%%%%%%%%%%##///////////(#%%%%%%%%#(***///////\n",
    ",*************,,**,,,************,,,,,/(##((((####%%%%%%%%%%%%%%%%%%%(/**/(((#((((#((//(#%%%%%%%%%%%%%%%%%#(((((((((##%%%%%%%%%%#/**///////\n",
    ",******************************,,,,,,,*(#%#%%%%%%%%%%%%%%%%%%%%%%%%%%#(**/((#(#(((#((//(#%%%%%%%%%%%%%%%%%%%%%%%#%#%%%%%%%%%%%%%#(**///////\n",
    ",*************,**************,****,,,,,/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*/((((#((((///(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%(/*///////\n",
    ",*************************************,*/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(////////////(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#/**/////*\n",
    ",******////****///////////////////////***/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%####(((((((###%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(********\n",
    ".,*,****///////////////////////////////***/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*******\n",
    ".,,,,*****//////////////////////////*******(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(*******\n",
    ".,,,,,,***********/////////////////********/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%(*******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(898, 200, 200, 3)\n",
      "(100, 200, 200, 3)\n",
      "(898, 1)\n",
      "(100, 1)\n",
      "(200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_shape,x=loadpath(image_paths_train+image_paths_test,200,200)\n",
    "y=np.concatenate((y_train, y_test), axis=0)\n",
    "# from keras.utils import to_categorical\n",
    "# y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)\n",
    "\n",
    "# y_train=y_train.transpose()\n",
    "# y_test=y_test.transpose()\n",
    "\n",
    "# y_train=np.matrix(y_train)\n",
    "# y_test=np.matrix(y_test)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1,random_state=420,shuffle=True)\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 196, 196, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 97, 97, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 95, 95, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 93, 93, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 20, 20, 128)       131200    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 17, 17, 128)       262272    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2100)              2421300   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1420)              2983420   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               181888    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 6,045,777\n",
      "Trainable params: 6,045,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Model,Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "# Basic model1\n",
    "\n",
    "M2 = Sequential()\n",
    "\n",
    "M2.add(Conv2D(32, kernel_size=(3, 3),strides=(1,1),activation='relu',input_shape=input_shape))\n",
    "M2.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "M2.add(MaxPooling2D(pool_size=(3, 3),strides=(2,2)))\n",
    "\n",
    "M2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "M2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "M2.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "\n",
    "M2.add(Conv2D(128, (4, 4), activation='relu'))\n",
    "M2.add(Conv2D(128, (4, 4), activation='relu'))\n",
    "\n",
    "M2.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "\n",
    "M2.add(Flatten())\n",
    "\n",
    "M2.add(Dense(2100,activation='relu'))\n",
    "\n",
    "M2.add(Dense(1420,activation='relu'))\n",
    "\n",
    "M2.add(Dense(128, activation='relu'))\n",
    "\n",
    "M2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "M2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 898 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "512/898 [================>.............] - ETA: 50s - loss: 1.1096 - acc: 0.5117 "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "history_cb1 = LossHistory()\n",
    "\n",
    "batch_size=256\n",
    "epochs=100\n",
    "M2.compile(loss='binary_crossentropy',optimizer=keras.optimizers.Adadelta(lr=0.01),metrics=['accuracy'])\n",
    "\n",
    "M2.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test),callbacks=[history_cb1])\n",
    "\n",
    "score = M2.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2.save('Skynet_M2')\n",
    "# model = keras.models.load_model('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "model2Hist = history_cb1\n",
    "plt.plot(model2Hist.acc)\n",
    "plt.plot(model2Hist.val_acc)\n",
    "plt.title('Model 2')\n",
    "plt.legend((\"Training\", \"Testing\"), loc=\"best\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#        ,@@@@@@@@@@,,@@@@@@@%  .#&@@@&&.,@@@@@@@@@@,      %@@@@@@%*   ,@@@%     .#&@@@&&.  *&@@@@&(  ,@@@@@@@%  %@@@@@,     ,@@,          \n",
    "            ,@@,    ,@@,      ,@@/   ./.    ,@@,          %@%   ,&@# .&@&@@(   .@@/   ./. #@&.  .,/  ,@@,       %@%  *&@&.  ,@@,          \n",
    "            ,@@,    ,@@&%%%%. .&@@/,        ,@@,          %@%   ,&@# %@& /@@,  .&@@/,     (@@&%(*.   ,@@&%%%%.  %@%    &@#  ,@@,          \n",
    "            ,@@,    ,@@/,,,,    ./#&@@@(    ,@@,          %@@@@@@%* /@@,  #@&.   ./#&@@@(   *(%&@@&. ,@@/,,,,   %@%    &@#  .&&.          \n",
    "            ,@@,    ,@@,      ./,   .&@#    ,@@,          %@%      ,@@@@@@@@@% ./.   .&@# /*.   /@@. ,@@,       %@%  *&@&.   ,,           \n",
    "            ,@@,    ,@@@@@@@% .#&@@@@&/     ,@@,          %@%     .&@#     ,@@/.#&@@@@&/   /%&@@@@.  ,@@@@@@@%  %@@@@@.     ,@@,          \n",
    ",*************,,*/(((((//,,*(#%%%%%%%%%%%%%%%#(*,,,****************************************************,*/(((((((((/((((////****/((##%%%%%%\n",
    ",*************,,//((((((//,,*(%%%%%%%%%%%%%%%%%##/*****************************************************,,*/(///(//////****//((##%%%%%%%%%%%\n",
    ",************,,*/(((((((//***/#%%%%%%%%%%%%%%%%%%%#(/***************************************************,*//////////*//((#%%%%%%%%%%%%%%%%%\n",
    ",***********,,*////////////***/##%%%%%%%%%%%%%%%%%%%##(*,***********************************************,,*////////(###%%%%%%%%%%%%%%%%%%%%\n",
    ",**********,,,*/*******//////**/(#%%%%%%%%%%%%%%%%%%%%%#(/**********************************************,,,***/(##%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    ",*********,,,,*************///***/(#%%%%%%%%%%%%%%%%%%%%%%#(/***********************************,****,****/((#%%%%%%%%%%%%%%%%%%%%%%%%%%%%#\n",
    ",*********,,,***************//****/(##%%%%%%%%%%%%%%%%%%%%%%##//**************//////////////////////((#####%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(\n",
    ",********,,,,***********************/(#%%%%%%%%%%%%%%%%%%%%%%%##################%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(/\n",
    ",*******,..,***********************,,*/##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%###((//\n",
    ",*******,.,,***********************,,,,*(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(//**//\n",
    ",******,.,,,************************,,,,*/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(//*******\n",
    ",*****,,,,,********,***,,,,,,,,,,,,*,,,,,,*/(######%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(/**********\n",
    ",*****,..,*******,,,,,,,,,,,,,,,,,,,,,,*,,,,*///((#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%###(/************\n",
    ",*****,,,*******,,,,,*,,,,,,,,,,,,,,,,,****,,,*/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#######(//**************\n",
    ",****,.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,**,,,/(%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#((//******************\n",
    ",***,..,,,,,,,,,,,,,,,,,,,,,,,,,,,,,..,,,,,,,*(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*******************\n",
    ",**,,.,,,,,,,,,,,,,,,,,,,,,,,,,,.......,,,,,,/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#####%%%%%%%%%%%%%%%%#(/******************\n",
    ",**,..,,,,,,,,,,,,,,,,,,,,,,,,,......,,,*,,,*(#%%%%%%%%##(((/(##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(((/*/((#%%%%%%%%%%%%%%#(/*****************\n",
    ",*,..,,,,,,,,,,,,,,,,,,,,,,,,,,,.....,,**,,*/#%%%%%%%##((((*,**/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%##((##/,,,*(#%%%%%%%%%%%%%%#(*****************\n",
    ".*,.,,,**,,,,,,,,,,,,,,,,,,,,,,,,,,*****,,,/(%%%%%%%%#(//(#/,..*/#%%%%%%%%%%%%%%%%%%%%%%%%%%%#(//(#/,..,/(#%%%%%%%%%%%%%%#/*****///////////\n",
    ".,..,,,,,,,,,,,,,,,,,,,,,,,,,,*,,*******,,,(#%%%%%%%%#(*,,,....,/#%%%%%%%%%%%%%%%%%%%%%%%%%%%#(*,,,....,/(#%%%%%%%%%%%%%%#(*,**////////////\n",
    ".,..,,,,,,,,,...........,,,,,,*,********,,*(#%%%%%%%%%#(/*,,...,/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*,,..,*/##%%%%%%%%%%%%%%%#(***////////////\n",
    "...,,,,,,,................,,*,**********,,/#%%%%%%%%%%%%#((////((#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##((///(#%%%%%%%%%%%%%%%%%%(/**////////////\n",
    " ..,,,,,,.................,,,**********,,*(#%%%%%%%%%%%%%%%%%%#%%%%%%%%#((///((#%%%%%%%%%%%%%%%%%%%%%#%%%%%%%%%%%%%%%%%%%%%#/**////////////\n",
    ".,,,,,,,,.................,,***********,,/(####%%%%%%%%%%%%%%%%%%%%%%%%#(/*,,,*(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*////////////\n",
    ".,***,,,,,,..............,,,**********,..,***//((##%%%%%%%%%%%%%%%%%%%%%%%##((##%%%%%%%%%%%%%%%%%%%%%%%%%##(((((((((###%%%%%#/**///////////\n",
    ".*****,,,,,,,,,,,,,,,,,,,*************,..,*******/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##///*//////((#%%%%%#(**///////////\n",
    ".****************/******/***////*****,.,*///////**/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(////////////(#%%%%%#/**//////////\n",
    ".***********************/////*******,..,*//////////(#%%%%%%%%%%%%%%%%%%%%##########%%%%%%%%%%%%%%%%%%%%#(///////////*/(#%%%%%#(***/////////\n",
    ".************************///********,..,*//////////#%%%%%%%%%%%%%%%%%%#(//*****///(((##%%%%%%%%%%%%%%%%#(///////////**/##%%%%##/***////////\n",
    ".***********************************,.,,***///////(#%%%%%%%%%%%%%%%%#(/*,,,*//((((////(#%%%%%%%%%%%%%%%#((////////////(#%%%%%%#(*********//\n",
    ",***********,,,*,,*,,**************,,,*//******//(#%%%%%%%%%%%%%%%%%#(*,,*/(((#####(((((#%%%%%%%%%%%%%%%##///////////(#%%%%%%%%#(***///////\n",
    ",*************,,**,,,************,,,,,/(##((((####%%%%%%%%%%%%%%%%%%%(/**/(((#((((#((//(#%%%%%%%%%%%%%%%%%#(((((((((##%%%%%%%%%%#/**///////\n",
    ",******************************,,,,,,,*(#%#%%%%%%%%%%%%%%%%%%%%%%%%%%#(**/((#(#(((#((//(#%%%%%%%%%%%%%%%%%%%%%%%#%#%%%%%%%%%%%%%#(**///////\n",
    ",*************,**************,****,,,,,/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*/((((#((((///(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%(/*///////\n",
    ",*************************************,*/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(////////////(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#/**/////*\n",
    ",******////****///////////////////////***/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%####(((((((###%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(********\n",
    ".,*,****///////////////////////////////***/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*******\n",
    ".,,,,*****//////////////////////////*******(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(*******\n",
    ".,,,,,,***********/////////////////********/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%(*******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_shape,x=loadpath(image_paths_train+image_paths_test,250,250)\n",
    "y=np.concatenate((y_train, y_test), axis=0)\n",
    "# from keras.utils import to_categorical\n",
    "# y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)\n",
    "\n",
    "# y_train=y_train.transpose()\n",
    "# y_test=y_test.transpose()\n",
    "\n",
    "# y_train=np.matrix(y_train)\n",
    "# y_test=np.matrix(y_test)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1,random_state=420,shuffle=True)\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model,Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
    "# Basic model1\n",
    "\n",
    "M3 = Sequential()\n",
    "\n",
    "M3.add(Conv2D(32, kernel_size=(3, 3),strides=(1,1),activation='relu',input_shape=input_shape))\n",
    "M3.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "M3.add(BatchNormalization())\n",
    "\n",
    "M3.add(Dropout(.200000000000000000000000000000000000000000001))\n",
    "\n",
    "M3.add(MaxPooling2D(pool_size=(3, 3),strides=(2,2)))\n",
    "\n",
    "M3.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "M3.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "M3.add(Dropout(.200000000000000000000000000000000000000000001))\n",
    "\n",
    "M3.add(BatchNormalization())\n",
    "\n",
    "M3.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "\n",
    "M3.add(Conv2D(128, (4, 4), activation='relu'))\n",
    "M3.add(Conv2D(128, (4, 4), activation='relu'))\n",
    "\n",
    "M3.add(BatchNormalization())\n",
    "\n",
    "M3.add(Dropout(.200000000000000000000000000000000000000000001))\n",
    "\n",
    "M3.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "\n",
    "M3.add(Conv2D(256, (4, 4), activation='relu'))\n",
    "M3.add(Conv2D(256, (4, 4), activation='relu'))\n",
    "\n",
    "\n",
    "M3.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "\n",
    "M3.add(BatchNormalization())\n",
    "\n",
    "M3.add(Dropout(.200000000000000000000000000000000000000000001))\n",
    "\n",
    "M3.add(Flatten())\n",
    "\n",
    "M3.add(Dense(2100,activation='relu'))\n",
    "\n",
    "M3.add(Dense(1420,activation='relu'))\n",
    "\n",
    "M3.add(Dense(720,activation='relu'))\n",
    "\n",
    "M3.add(Dense(128, activation='relu'))\n",
    "\n",
    "M3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "M3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#        ,@@@@@@@@@@,,@@@@@@@%  .#&@@@&&.,@@@@@@@@@@,      %@@@@@@%*   ,@@@%     .#&@@@&&.  *&@@@@&(  ,@@@@@@@%  %@@@@@,     ,@@,          \n",
    "            ,@@,    ,@@,      ,@@/   ./.    ,@@,          %@%   ,&@# .&@&@@(   .@@/   ./. #@&.  .,/  ,@@,       %@%  *&@&.  ,@@,          \n",
    "            ,@@,    ,@@&%%%%. .&@@/,        ,@@,          %@%   ,&@# %@& /@@,  .&@@/,     (@@&%(*.   ,@@&%%%%.  %@%    &@#  ,@@,          \n",
    "            ,@@,    ,@@/,,,,    ./#&@@@(    ,@@,          %@@@@@@%* /@@,  #@&.   ./#&@@@(   *(%&@@&. ,@@/,,,,   %@%    &@#  .&&.          \n",
    "            ,@@,    ,@@,      ./,   .&@#    ,@@,          %@%      ,@@@@@@@@@% ./.   .&@# /*.   /@@. ,@@,       %@%  *&@&.   ,,           \n",
    "            ,@@,    ,@@@@@@@% .#&@@@@&/     ,@@,          %@%     .&@#     ,@@/.#&@@@@&/   /%&@@@@.  ,@@@@@@@%  %@@@@@.     ,@@,          \n",
    ",*************,,*/(((((//,,*(#%%%%%%%%%%%%%%%#(*,,,****************************************************,*/(((((((((/((((////****/((##%%%%%%\n",
    ",*************,,//((((((//,,*(%%%%%%%%%%%%%%%%%##/*****************************************************,,*/(///(//////****//((##%%%%%%%%%%%\n",
    ",************,,*/(((((((//***/#%%%%%%%%%%%%%%%%%%%#(/***************************************************,*//////////*//((#%%%%%%%%%%%%%%%%%\n",
    ",***********,,*////////////***/##%%%%%%%%%%%%%%%%%%%##(*,***********************************************,,*////////(###%%%%%%%%%%%%%%%%%%%%\n",
    ",**********,,,*/*******//////**/(#%%%%%%%%%%%%%%%%%%%%%#(/**********************************************,,,***/(##%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    ",*********,,,,*************///***/(#%%%%%%%%%%%%%%%%%%%%%%#(/***********************************,****,****/((#%%%%%%%%%%%%%%%%%%%%%%%%%%%%#\n",
    ",*********,,,***************//****/(##%%%%%%%%%%%%%%%%%%%%%%##//**************//////////////////////((#####%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(\n",
    ",********,,,,***********************/(#%%%%%%%%%%%%%%%%%%%%%%%##################%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(/\n",
    ",*******,..,***********************,,*/##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%###((//\n",
    ",*******,.,,***********************,,,,*(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(//**//\n",
    ",******,.,,,************************,,,,*/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(//*******\n",
    ",*****,,,,,********,***,,,,,,,,,,,,*,,,,,,*/(######%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(/**********\n",
    ",*****,..,*******,,,,,,,,,,,,,,,,,,,,,,*,,,,*///((#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%###(/************\n",
    ",*****,,,*******,,,,,*,,,,,,,,,,,,,,,,,****,,,*/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#######(//**************\n",
    ",****,.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,**,,,/(%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#((//******************\n",
    ",***,..,,,,,,,,,,,,,,,,,,,,,,,,,,,,,..,,,,,,,*(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*******************\n",
    ",**,,.,,,,,,,,,,,,,,,,,,,,,,,,,,.......,,,,,,/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#####%%%%%%%%%%%%%%%%#(/******************\n",
    ",**,..,,,,,,,,,,,,,,,,,,,,,,,,,......,,,*,,,*(#%%%%%%%%##(((/(##%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(((/*/((#%%%%%%%%%%%%%%#(/*****************\n",
    ",*,..,,,,,,,,,,,,,,,,,,,,,,,,,,,.....,,**,,*/#%%%%%%%##((((*,**/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%##((##/,,,*(#%%%%%%%%%%%%%%#(*****************\n",
    ".*,.,,,**,,,,,,,,,,,,,,,,,,,,,,,,,,*****,,,/(%%%%%%%%#(//(#/,..*/#%%%%%%%%%%%%%%%%%%%%%%%%%%%#(//(#/,..,/(#%%%%%%%%%%%%%%#/*****///////////\n",
    ".,..,,,,,,,,,,,,,,,,,,,,,,,,,,*,,*******,,,(#%%%%%%%%#(*,,,....,/#%%%%%%%%%%%%%%%%%%%%%%%%%%%#(*,,,....,/(#%%%%%%%%%%%%%%#(*,**////////////\n",
    ".,..,,,,,,,,,...........,,,,,,*,********,,*(#%%%%%%%%%#(/*,,...,/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*,,..,*/##%%%%%%%%%%%%%%%#(***////////////\n",
    "...,,,,,,,................,,*,**********,,/#%%%%%%%%%%%%#((////((#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##((///(#%%%%%%%%%%%%%%%%%%(/**////////////\n",
    " ..,,,,,,.................,,,**********,,*(#%%%%%%%%%%%%%%%%%%#%%%%%%%%#((///((#%%%%%%%%%%%%%%%%%%%%%#%%%%%%%%%%%%%%%%%%%%%#/**////////////\n",
    ".,,,,,,,,.................,,***********,,/(####%%%%%%%%%%%%%%%%%%%%%%%%#(/*,,,*(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*////////////\n",
    ".,***,,,,,,..............,,,**********,..,***//((##%%%%%%%%%%%%%%%%%%%%%%%##((##%%%%%%%%%%%%%%%%%%%%%%%%%##(((((((((###%%%%%#/**///////////\n",
    ".*****,,,,,,,,,,,,,,,,,,,*************,..,*******/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##///*//////((#%%%%%#(**///////////\n",
    ".****************/******/***////*****,.,*///////**/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(////////////(#%%%%%#/**//////////\n",
    ".***********************/////*******,..,*//////////(#%%%%%%%%%%%%%%%%%%%%##########%%%%%%%%%%%%%%%%%%%%#(///////////*/(#%%%%%#(***/////////\n",
    ".************************///********,..,*//////////#%%%%%%%%%%%%%%%%%%#(//*****///(((##%%%%%%%%%%%%%%%%#(///////////**/##%%%%##/***////////\n",
    ".***********************************,.,,***///////(#%%%%%%%%%%%%%%%%#(/*,,,*//((((////(#%%%%%%%%%%%%%%%#((////////////(#%%%%%%#(*********//\n",
    ",***********,,,*,,*,,**************,,,*//******//(#%%%%%%%%%%%%%%%%%#(*,,*/(((#####(((((#%%%%%%%%%%%%%%%##///////////(#%%%%%%%%#(***///////\n",
    ",*************,,**,,,************,,,,,/(##((((####%%%%%%%%%%%%%%%%%%%(/**/(((#((((#((//(#%%%%%%%%%%%%%%%%%#(((((((((##%%%%%%%%%%#/**///////\n",
    ",******************************,,,,,,,*(#%#%%%%%%%%%%%%%%%%%%%%%%%%%%#(**/((#(#(((#((//(#%%%%%%%%%%%%%%%%%%%%%%%#%#%%%%%%%%%%%%%#(**///////\n",
    ",*************,**************,****,,,,,/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*/((((#((((///(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%(/*///////\n",
    ",*************************************,*/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(////////////(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#/**/////*\n",
    ",******////****///////////////////////***/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%####(((((((###%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(********\n",
    ".,*,****///////////////////////////////***/#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%#(/*******\n",
    ".,,,,*****//////////////////////////*******(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##(*******\n",
    ".,,,,,,***********/////////////////********/(#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%(*******"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "history_cb2 = LossHistory()\n",
    "\n",
    "batch_size=256\n",
    "epochs=100\n",
    "M3.compile(loss='binary_crossentropy',optimizer=keras.optimizers.Adadelta(lr=0.01),metrics=['accuracy'])\n",
    "\n",
    "M3.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test),callbacks=[history_cb2])\n",
    "\n",
    "score = M3.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M3.save('Skynet_M3')\n",
    "# model = keras.models.load_model('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "model3Hist = history_cb2\n",
    "plt.plot(model3Hist.acc)\n",
    "plt.plot(model3Hist.val_acc)\n",
    "plt.title('Model 3')\n",
    "plt.legend((\"Training\", \"Testing\"), loc=\"best\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
